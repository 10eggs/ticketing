$npm init -y // all default on YES
$npm install typescript ts-node-dev express @types/express

$tsc --init


#This time we are running Kubernetess stuff directly, straight after creation of new service
warning: LF will be replaced by CRLF in ticketing/auth/package-lock.json.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in ticketing/auth/package.json.
The file will have its original line endings in your workingss





#If you did not see your server restart after changing the index.ts file, do the following:
#Open the package.json file in the ‘auth’ directory
#Find the ‘start’ script
#Update the start script to the following:
$ts-node-dev --poll src/index.ts

#To run skaffold
$skaffold dev

#To prevent problem with cert in chrome
$thisisunsafe

#Remove dir from git
$git rm -r --cached myFolder

#To interact between TS and Mongoose we need to write some custom code as mongoose doesn't support TS natively

#Mongoose User Model - Represents the entire colletion of users
#Mongoose User Document - Represents one single user
#Initially there is no check against constructor properties, which means you can do typo in property name for example and TS will not complain

#Creating User Model
#1. Create scheme - tell mongoose specifically about all the different properties that model will going to have
#2. Create a model in MongoDB
#3. ISSUE no1: When I'll try to create User object with passing any arguments, there is no check provided by TS, so I can do a mistake by passing wrong arguments
#4. Solution - create an interface which describe constructor properties. Next, use new build() function to use interface
#5. build() function need to be connected to User model. We can achieve it by add 'static' property to the model
#6. Initially, we'll end up with error - TS doesn't understand what does it mean to assign a property to a static object
#7. Hence we need to boost our Model to be aware of this function
#8. Solution - introduce another interface to describe what properties our User model should have
#9. In UserModel interface we are introducing GENERICS
#10. After that our mongoose.model will have two generic arguments - any and UserModel
#11. ISSUE no2: Let's say I'd like to print my UserDocument in console - it shows me all properties, even these ones which are added by mongoose automatically.
#12. Solution: Introduce interface for User Document
#13. 

#Hashing Password
#1. Signup process
#2. Create salt
#3. Buffer - raw array of byte inside of it

#Middleware in Mongoose
#1. using .pre()
#2. using function rather than arrow function. Whenever we are calling middleware function we've got an access
# to Entity which we are going to persist to database by calling 'this' keyword - if we would use arrow function instead then 'this' refeering to context of entire file


#AUTHENTICATION STRATEGIES!
# To handle cookies we'll be using cookie-session package:
# npm install cookie-session @types/cookie-session
# to create JWT we need jsonwebtoken

#Useful links:
#https://www.base64decode.org/
#jwt.io

#Securely Storing Secrets with Kubernetes
#In order to do that - use Secret object in kubernetes
#Imperative approach (by using command):
$kubectl create secrete generic jwt-secret --from-literal=<KEY>=<VALUE>
#kubectl create secret generic jwt-secret --from-literal=JWT_KEY=9283hdin92unc9e0j2neAASUDH


#To get Secrets
$kubectl get secrets

#Mongo db returns '_id', which is usually called 'id'
 #This lines won't work in TS as TS can't detect if this env variable was created or not
  const userJwt = jwt.sign({
    id: user.id,
    email: user.email
  },process.env.JWT_KEY);

  #To mitigate this problem we are going to implement handler which detect during the boot process if env variable is there or not
  #EXCLAMATION MARK in typescript indicate that we have handled suggested error, and typescript shouldn't worry about it


#We can override the way how the javascript object is represented by JSON.stringify. To do so, we need to implement toJSON() method for our object, i.e.:
$const person = {name='Tomek',toJSON(){return 1;}}
#It always return 1

#SHORTCUT
#Ctrl+Shift+` to create new terminal.

#SHORTCUT
#ctrl+shift+p - open PANE
#ctrl+e - search files by name

#Middleware always run in order

#CurrentUser - to prevent access to cookies from the browser
#After creation of CurrentUser handler we want to introduce another middleware to set access to routes can be used by current user.
#


#INTRODUCING TESTS TO OUR PROJECT
#supertest doesn't manage cookie for us by default
#Why we are using SSR rather than CSR?

#1. Just to show how to handle it in microservices world,
#2. Better for mobile devices
#3. Better for SEO 


#Suggestion Regarding a Default Export Warning
#Information:
#Anonymous arrow functions cause Fast Refresh to not preserve local component state.

#Please add a name to your function, for example:
#Before
#export default () => <div />;
#After
#const Named = () => <div />;
#export default Named;


#Starting with Next.JS
#In each file inside pages directory we'll be exporting React components
#Next.js working differently than React router
#Whenever next.js started it is reading all the files from pages folder
#Next can distinct files by names and treat this filenames as a routes

#Making changes in ingress
#We've got two services set on port 3000
#If we've got many paths, ingress will try to match them in order
#So the best approach here is to use the most specific paths at the very beginning, and
#And leave generic ones at the end (for example /?(.*) means anything)

Problem with Kubernetess/Ingress
#Troubleshooting: 
#https://kubernetes.github.io/ingress-nginx/troubleshooting/
#kubectl get ing
#kubectl describe ing

#Next.js running in container cannot react on changes in file immmidiately - we need to do some changes there.


##CSS handling
#Bootstrap - global for whole proj
#First - create _app.js - critial to call it exactly the same


#Check how to handle braces for functions etc
#Short circut evaluation - &&. So we can use it as a check, x && f() , if x false we won't execute second part

#Server Side Rendering Overview
#How to make a request to currentUser while our application is build
#How SSR works:

#1. Inspect incoming request - determine set of components to show
#2. Call those components 'getInitialProps' static method
#3. Render each component with data from 'getInitialPros' one time
#4. Assamble HTML from all components, send back response


#Fetching data during SSR
#Differences between requesting data from server vs from the client
#We are receiving and error while we are trying to send a request from getInitialProps method in Next.js
#The reason why we get it is a Kubernetess


####  SUPER CRITICAL ###
#OPTION NO.1
# We are running next.js inside our CONTAINER
# So call done by the server from getInitialProps is done by node INSIDE our container,
so if we are not specify domain (we don't need to specify domain from client, as we know ticketing.dev = 127.0.0.1:80 )

#Two kind of step solution for it:
#1. Client(in this case next.js app) direct reach service
#In auth-depl.yaml we create a auth-srv service - So ANYTHING in our pod/inside our cluster
#can access this service, therefore the pod that it governs access to.
#So we can call our auth-service from next.js application, and as a domain nam we should pass service name auth-service.

#NOT THE BEST APPROACH - implies that our react will know exact service name for every different thing
#And not only svc names - also which route corresponding to which service

#OPTION NO.2
#Anytime we need to fetch data from a service inside of our kubernetes cluster,
#our next.js app needs to reach out ingress nginx which is already running inside the cluster

#We need to figure out how to make a request directly to ingress nginx when we are inside the cluster
#Next challenge is to get information stored in cookies - as we are running on server side we don't have an acces to the browser
#So we need to check the original,incoming request, extract cookies, and include it to call to ingress nginx

###Cross Namespace Service Communication###
#We can access another pod inside cluster by passing the cluster ip service name, i.e. http://auth-srv
#This is valid only when we are working in the same Namespace

#Namespace - is an element of kubernetess. Used for organizing different objects
#Most of our objects are in default Namespace
#We can't use auth-srv as it's not in default Namespace

#We need to introduce crossnamespace Communication
#Following is a pattern for domain namespace:
$http://NAMEOFSERVICCE.NAMESPACE.svc.cluster.local

#To check namespaces:
$kubectl get namespace

#To check all services in ingress-nginx namespace
$kubectl get services -n ingress-nginx

#So in our case:
$http://ingress-nginx.ingress-nginx.svc.cluster.local

#To avoid nasty naming - we need to introduce external name service

#238. When is getInitialProps called?
#So to introduce all above:
#Request from browser -> Use baseurl in axios of just empty stringify
#If rqeuest from next js during ssr - reach directly to auth svc // ingress-nginx
#Need to figure out where request come from - browser or SS?

#Two cases: Request from component // Request from  getIntiialProps
#Component - Always issued from the browser so use a domain of '',
#Might be executed from the client or the server! Needs to figure out what our env is so we can use the correct domain
#getInitialProps MAY BE executed from browser as well (in particular circumstances)
 
### REQUEST SOURCES ###
#1. Executed on the server
#   - hard refresh of pages
#   - clicking link from different domain
#   - typing url into address braces

#2. Executed from one page to another while in the app
#   - getInitialProps executed on the client

#To verify where it come from- check if window object exist
#Next thing is to check our ingress-srv.yaml file
#ATM routing rules are specified under host ticketing.dev
#Nginx needs to know about host which we'd like to reach
#If we are navigate inside our app we are including domain name in the request (ticketing.dev)
#If it's comming from browser - request can be easily inspect

#If we are doing it from server - there is no way to establish what domain it came from
#What we can do - pass options object to axios function()
#headers with host property
#To pass cookies to nginx we need extract it from incoming request
#getInitialProps will be provided with arguments - desctructing req object

#Also we don't need to specify our Host directly - instead we can get our host from headers
#This means this request in getInitialProps may be treated as proxy

#243.A Reusable API client
#Rather than having logic for handling requests from client/server in every file, we'd like to extract it into one place
#We are going to introduce buildClient
#So this is how it going to work
#Incoming request (with headers) -> Logic to build an instace of axios that works on current env -> precofigured version of axios that just works

#246. Reusable headers
#Needs wrap up <Component/> component with an extra content
#Rather than fetching data from two separate components we can centralize it and put this logic just inside one component
#By doing that we can pass fetched properties all way down
#CAUTION: At some point the the future we might have some component does needs to have some get initial props function in it
#So if we'd got two components with getInitialProps function it may be a bit challenging for us

#247. Moving getInitialProps
#So now we are moving our getInitialProps from index to AppComponent.
#We need to make sure that we build up our axios client because we are going to run into
#all these same issues around problems with our domain or the base url, depend upon whether running client/server 
#So need to import our build client custom functionality

#248. Issue with Custom App GetInitialProps
#It turns out that there are some problem with Custom App (_app) and getInitialProps
#In _app we are not working in the page - we are working in custom app component which is wrapping our page

#In Next.js we've got the differences between arguments passed to getInitialProps page and to custom component
#Arguments provided to the page are different than custom app component
#Page Component:
$PageComponent.geInitialProps(context) where context === {req,res}
#Custom App Component
#CustomAppComponent.getInitialProps(context) where context === {Component, ctx: {req,res}}

#Unfortunately when we tie get initial props to app component, you get initial props tie to app component do not get automatically invoked anymore
#We are passing down getInitialProps from AppComponent

#So in AppComponent.getInitialProps we've got an access to Landing Page component through context argument (first argument of this function)
#We are adding quick if statement to verify if page has an initial props defined - if not then pass empty object;

#250. Passing Props through
#So the information fetched in getInitialProps are papsed to the ApPComponent

#253. Signing out
#This call needs to be done from browser rather than server (so it can't be invoked from getInitialProps)
#Server doesn't know what to do with any cookies
#So call needs to be done from Component
#

#255. Share logic between services
#Options:
#1. Copy/Paste
#2. Git submodule (challenging)
#3. NPM Package

#257. NPM Organizations
#NPM Public registry
#NPM Package inside Organization
#NPM Private Registry

#NPM login: 10eggz
org: supafellas

#258. Publishing NPM Modules
#This is where package.json name & version become important
#Format for name: 
#@nameoforganization/nameofpackage

#Add package: npm publish --access public
#If error - npm login

#259. Project Setup
#So we might find problems with our TS implementation
#Hence our common library will be written as Typescript and published as javascript
#To do that we need to install a few dependencies
$tsc --init
$npm install typescript del-cli --save-dev
#const delay = t => new Promise(resolve => setTimeout(resolve, t));

#buid command - run tsc compiler, find index.ts file and turn it in js code
#Following changes was done for tsconfig.json:
$uncomment declaration
#It makes sure that when we turn our ts into js its going to also generate a type definition file, 
#so even if we install this module into a service that uses ts, we'll still have a type definition file

$uncomment outdir
#After generating our js code we're going to take everything got generated and stick it into a new folder inside of our common dir called build

#also del-cli tool was installed to make sure that every time when we are building our project we are cleaning build directory

#261. An Easy Publish command
#This 'main' path in package.json is defining exactly what file we import whenever we attempt to import this module
#So changes are made for main and types property. Also "files" was added - tell npm what set of files inside of our project we want to
#get included inside the final published version of our package

#When we are doing changes for our module we can change version manually in package.json or use built-in commands either
$npm version patch

#Optionally - read about npm versioning sematnic
#After patch incremented:
$npm run build
#npm publish

#263. Updating Import Statements
#1. Publish changes (by running our script)
#npm update <name_of_module>


#ORG name: @supafellas/common
#How do we know that our container is running the correct version of that dependency?
#Start shell inside the pod
$kubectl exec -it <name-of-service> shell
$


//~~    TICKETING Service   ~~//
#Steps to prepare another service:

#1. Create package.json, install dependencies,
#2. Write Dockerfile
#3. Create index.ts to run project
#4. Build image, push to docker hub
#5. Write k8s file for deployment, service
#6. Update skaffold.yaml to do file sync for ticketing
#7. Write k8s file for Mongodb deployment, service


#269. Mongo Connection URI
#In tickets-depl add new env variable for mongo URI

#271. Test-First approach
# Writing some tests before we start writing implementation
# For ticketing we want to have a currentUser handler in place just for two routes
# We can pass it as a second argument for post() method

#274. Fake AUTHENTICATION
#We cant use our pre-built authenticaiton helper method from Auth Service, as we want to stay in tickets service context
#A bit refactoring for global.signin

#Twilio
#SendGrid
#base64decode.org

#When we are working with supertest we need to put all cookies into an array

#278. Validating Title and Price
#To validate request we need to import body() from 'express-valdiator'
# .not() - check if provided
# .isEmpty() - provided by empty
#.

#280. Reminder On Mongoose with Typescript
#Create model in typescript
#1. Add 3 interfaces:
#   a)UserAttr - describe properties required for create this record
#   b)UserDoc - describe what properties this record will have after save
#   c)UserModel - all properties which we'd want to assign to the model
#2. Model represent entire collection of data
#3. Document represents one single record
#4. Schema - all properties we want it
#5. Mongo save record with '_id' (in common dbs it is use to be id)
#6. add pre save hook (as we are hashing password in auth)
#7. We defined build function - entire goal of this was to just allow typescript to do some validation
#or type checking on the properties we were trying to use to create a new record
#that was the only reason we made Build
#whenever we tried to create a record directly by using that user model, theres not any type checking that goes on
#with the attributes we pass in
#that's why we need this build thing
#8. Create model, export it

#281. Creation via Route handler
#Interesting part here is that when we are creating our record in route handler (ticket record)
#We have an access to currentUser property, as it was determined by middleware before it came to route handler
#requireAuth is checking if user is authenticated, however TS complaing on req.currentUser as it can't determine if currentUser exist or not
#To disable this warning - use exclamation mark after property name
# BACKTICK -> `
#For express default status is 200


#284. Trying to figure out why we are getting error 400 (we are expect to have 404)
#Instead of change common module we are doing changes in node modules directly (not recommended);


non bene pro toto libertas venditur


#293. NATS Streaming Server
#NATS (event sharing) and NATS Streaming Server - different things
#NATS Streaming Server is build on top of NATS

#When we have a command which we want to run when container is up and running, then we are adding it in spec/container/args[] as an array

#What NATS Streaming Server?
#Differences between custom implementatios and NATS Streaming Server
#We are using CHANNELS(topics) in NATS

#To Interact with NATS Streaming we'll need to use client library (node-nats-streaming)
#Apply ts config by using tsc --init

#To connect to NATS Pod we will send a message to ingress-nginx (nats working inside kubernetess)
#Easier way is to expose NATS pod by using NodePort Service
#Third option - stricly for dev purposes
#Run k8s command inside the cluster to port-forward to the specific pod

//first port is port on my local machine, second port is from NATS pod 
#kubectl port-forward nats-depl-87ff64fc5-6znrt 4222:4222

#Publishing Events

#In NATS we can't share directly plain js objects, we need to pares it to json (string);
#In the upcoming lecture, I will show typing rs in my terminal to restart the ts-node-dev instance.
#The ts-node-dev library recently released a change that disables this restart behavior by default.
#To enable it, you need to update the two scripts we added to the package.json file.  Update the two scripts to the following:

#ctrl+shift+5 - split terminal
#alt+left arrow/right arrow <- switch
#to restart node.dev type $rs

#Important methods from message
//Channel
$getSubject();

#Msg number
$getSequence();

#Actual data included in msg
$getData();

#Second paramter for nats.connect is clientId
#NATS streaming server never wants to see duplicate client id

#305. Queue Groups
# If we've got multiple copies or multiple instances of the same services, 
# we want to make sure that incoming event is only going to go to one of them

# In our channel, we are going to create Queue group
# We can have multiple queue groups in single channel
# Whenever we get an event coming into created channel NATS streaming is going to look at all the different groups we have
# It's then going to more or less randomly select one of the members out of every one of these groups
# And send the event onlt one of those members

# Potential naming convention for this group will be something like 'service-name-queue-group'
# 

# 306. Manual Ack Model
# Default behavior - if we end up with any kind of error inside of our subscription, when we receive that event
# the event is essentially lost and we do not get some follow up opportunity to process it again or anything like that
# setManualAckMode(true) help us with this issued
# 307. Client Health Checks

# When nats-depl was created we exposed port number 8222 for monitoring purposes - time to use it!
# Infromation about channels which NATS already running
# http://localhost:8222/streaming/channelsz?subs=1

# When subscriber is restarted it takes some amount of time to delete it from the list of subscribers
# NATS assuming that there were some temporary conneciton issues and everything will back soon
# Behind the scene ackMode trying to reach restarted service - that's why we can observe this message delay after restarting subscriber
# (NATS trying to send message to killed subscriber)

# How can we help NATS understand that when one of these clients goes offline, its not coming back?
# Two options
# 1. nats-depl params:
# -hbi 5s(heartbeat) - little request that nats is continously sending every 5s (param) to check if client is up and running
# -hbt 5s - how long each client has to respond
# - hpf - number of times that each client can fail before that streaming server is going to assume that connection is dead and governs

#308. Graceful Cient Shutdown
# We'd like to help NATS to figure out which service is really turned off by adding few additional lines of code


#309. Core concurrency issues
#Dispatch means read message/event basically
# Examples:
# a) One listener migh run more quickly than another
# and others...

#Solutions (possible solutions which doesnt work :P):
#1. Run only one copy of svc //performance
#2. Handle every error //cost
#3. Share state between services of last event processed //performance + limited globally for all of our different accounts to only processing exactly one update in a time
#4. Last event processed tracked by resource id // different queuest based on resource id
#   In this case(have restarted sequence per resource id) we need to have separate channels
#   In NATS - max 1000 channels
#5. Another idea is to persist events in publisher database:
#   a) send message to NATS
#   b) NATS sending back (to publisher) a message id to dispatch (now publisher knows what is the latest message id for reqsource)
#   c) NATS sending event to service, where it is dispatched and processed
#   d) Sequence number (generated by channel) is saved in db
#   e) So the coming requests from Publisher needs to know about last sequence - then last seq number is compared with seq number stored in final destination

#So how to solve this concurrency issues IN REAL?
#BIG CLAIM - example with bank account shows us that system was bad designed. So we tried to use NATS to fill the gap in architecture (it is not the best option)

#312. How to fix concurrency issues - DIAGRAMS


#314. Event redelivery
# Let's say service just broke out. We want to have something what would allow us to get all events which are pending in NATS
# To do so we need to add another option for subscriptionOptions() for our nats client
# setDeliverAllAvailable() give us a chance to get all pending messages
# However it's not good when you'll restart your service which send back 1kk messages

#315. Durable subscription
#Create Durable submodule
#NATS knows which subs are durable, and storying all processes with flags indicate message was proccessed or not
#If sub will lose connection, straight after restart it'll be provided with unproccessed messages
#Question here is - do we still need to have setDeliveryAllAvailable() option in?
#Answer - yes. It runs only once when we run service which has durable subscription (very first run of the service)
#Then messages will be provided to listener, and will be moved in NATS to durable subscription area

#For now it doesn't work as expected - setDeliveryAllAvailable() is getting whole list of events every time when restarted
#As NATS expecting that our restarted service (service which lose connection) will never come back, so durable sub is deleted

#Way to handle this - introduce queue group
#Even if there is no services listening, NATS will remember durable subscription

#317. Reusable NATS Listener

#319. Extending the Listener
#IF our business logic fail in onMessage handler, we want to just allow this message to time out
#to fail delivery essentially so Nats attemps to re deliver it automatically at some point
#If everything is OK then msg.Ack() needs to be invoked


#321. Lev TS for listener validation
#Need to find a way to match subject with message data (to not allow user to put wrong message against particular channel)
#We'll end up with strong mapping between subject names and event data

#Introduce ENUMS
#Enum for every subject
#Interface for any event


#328. Custom Publisher
#330. Awaiting event publication
#publish funciton needs to return promise. Inside that promise function we're going to resolve it when callback function is invoked,
#and reject if callback function is invoked with an error.

#Downsize of common module is that all pub/sub generics are written in TS and can be consumed only by TS Code.
#Alternatives are JSON Schema, Protobuf, Apache Avro

#It's worth to re-run NATS to clean rubbish data
#For publisher subject we need this type annotation to make sure that we'll never try to change the value of subject
#Data to event shold be from DB not from the request (to stay consistent with presave/save hooks in mongo db)

#337 - SINGLETON for NATS client
#When we using mongoose it knows that we are connected to instance of mongodb, that's why from every location in our project (dir)
#We are speaking to single instance of mongo db

#In case of NATS client is a bit different as NATS don't know if any connection was established already
#We need to share NATS client across all

#341. Singleton implementation
#Question mark for property which may be initialize later on

#natsWrapper started with lower case as this is one and only instance of this class (singleton)
#cluster id - in nats-depl you can find flag -cid which is cluster id
#for natsWrapper url of the client will be an url to the service which is governed by nats-depl
#metadata - nats-srv
#port - 4222


#343. Every time when our process is about to be stopped (SIGINT or SIGTERM) we want to stop
#WE dont want to have process.exit() in one of hidden method which turns off our application completely (as we had for our listener example)
#We should not invoke process.exit() from nats-wrapper class - instead we can close it from index();

#347. Event Bus
#Rather than emitting event to event bus we'd like to capture this event in separate database
#In separate process or some separate piece of code, something outside of our route handler we can have some code to watch Event Collection
#And it takes note every time when we emit event to it 

#Also we need to have a mechanism which prevent situation where DB with record is updated, but Event is not 
#If this is a case then we need to have some way to do UNDO for DB transaction
#We need to use Database TRANSACTION

#348. Fixing tests
#We are using jest redirect import feature (we don't want to import NATSWrapper)
#Instead we are going to import fake copy of NatsWrapper


#352, Ensuring Mock Invocations
#Rest mock data before every single test


#353. NATS Env Variables
#Need to add more environment variables to ticket-deployment
#ClusterId,ClientId,Url for NATS
#Problem with client id - we can't have same client id if we want to run ticketig service multiple times. ClientID
#needs to be unique for every client that we have connecting to NATS

#At some point in the time in the future it would be nice to be able to look at logs from NATS server and recognize what NATS clients
#were connected when. So NATS Client Id should match our running service. We want to know what each copy of ticket service is doing (every replica
will have separate NATS client)
#We want to use name of the pod as a client id
#NATS_CLIENT_ID is getting value from metadata.name


#355. The Oreder Service

#360. Subtle Service Coupling
#Express allow us to use validators (by express-validator). When we are using requireAuth in our route, we need to put all validator
#inside the array

#WE WILL IMPLEMENT IT BUT IT IS NOT THE BEST PRACTICE!
#In order service we don't want to implement validation agaisnt ticketid type eq MongoGUID, as this would be a coupling to Ticket Service (we may
# want to replace this service as some point by another service, that's why we need to stay agnostic)


#361. Associating Orders and tickets
#Mongoose ref/population feature

#cmd+shift+p = command pallete -> reload window

#365. Three potential scenarios:
#1. To associate an existing Order and Ticket together;
#2. To associate an existing Ticket with a *new* Order
#3. To fetch an existing Order from the databse with its associated Ticket


#366. Defining the Ticket Model
#We will have different definition of what ticket is between different services
#The reason why we are handling it in this way is that order services does not need to know all informations about service
#There is just few of them which we take care off  


#368. $ - special mongo operator 
#369. Convenience Document methods
#In Ticket model we'll add an extra methods

#ticketSchema.statics - adding method directly to the ticket model itself.
#Ticket object - allow us to get access to the overall collection

#If you want to add a new method to the document - ticketSchema.methods
#for methods we are using function keyword instead of arrow function ()
#We are going to use function keyword as mongoose is built in old-fashioned way (? :D) - we need to use this keyword to get access to the object
# so this will point to the ticket document we just called isReserved on

#To have one source of OrderStatus we are not going to import OrderStatus separately in Order, ticket, and new handler
#We are importing OrderStatus to our Order model, and then exporting it again - this propagation allow us to keep codebase cleaner,
#Every related component is sticked to Order model


test against mongodb objectid
// .custom((input: string)=>{
//   // mongoose.Types.ObjectId.isValid(input)
//   // mongoose.isValidObjectId(input)
// }) 


#377. Fetching a User's Orders
# To get related tickets (related to order) we will be using population system in Mongoose
# For test in index.test.ts we want to create an order for two tickets as a single user
# to do that we are sending two requests - reserve t1 and reserve t2
# In test to do validation we'd like to do some comparison on responses
# Problem with naming - should we call them 'response'?
# solution - destruct response and rename it in one line by using { responsePropertyName : variableName}

#ctrl+shift+[ or ] - expand/collapse code region


#384. Orders Service Events
#In order-created-event we are setting expiresAt as a string (not date) type as we'd like to do manual check for timezone etc.
#SIDE NOTE - in error-handler middleware I removed following link:
//http://expressjs.com/en/guide/error-handling.html


#Mongo is turning our date object into the string automatically - we don't want to do that as it creates timezone stamp. 
#Instead we'd like to have utc() timezone
#After correct assertion in our test it is a good practice to switch assertion to check if true eq true. (expect() should pass, not.expect() should fail)

#IT'S TIME FOR LISTENERS!
#REMINDERS:

#1. Queue group name
# Listeners are listening of channel, eg. ticket:created
# Two Listeners are joining queue-group called order-service
# Be being a member of this group that ensures that any time any event comes into this channel
# This event will be send only to one member of this queue group

#Event['data'] - we created an interface which definies what data will need to be passed to 'onMessage'

#Message msg - we are carry about ack() method there 
#We are calling ack when we SUCCESSFULLY  process a message or event


#396 Simple onMessage implementation
# TicketCreatedEvent - > order service listening because we need to store this ticket in local storage for order service. Data replication
# between services
# This allow us to not depend on other service as we've got all data in orders service
# We are facing an issue with ticketid - it is randomly generated, however we just want to have a link between these two tickets, ( for both data sources )
# To do that we need to update TicketModel file


#Run script to update package in all project directories

#Line2 in order model (order service) replaced - should be imported from npm module, it is imported directly instead
#Problem with exporting ENUMS


#413 Clear concurrency issues
# Orders and Tickets DBs are out of sync, we have to implement versioning
# Versioning in MongoDB is oob
# Concurrency Optimistic Control for Microservices - read
# Introducing new module - mongoose-update-if-current, which creates version as a timestamp
# __v - property for version, we'll want to change it for version
#ticketSchema.set('versionKey','version');

#When should we increment or include the version number of a record with an event?
#Whenever the primary service responsible for a record emits an event to describe a create update destroy to a record

#You can run a command inside the shell:
# db.tickets.find({})

By using //@ts-ignore annotation above declaration = all typescript complains are disabled

